{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial: Text Extraction and Filtering from Word Documents using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provided a step-by-step guide on how to extract, filter, and process text from Word documents using Python. With these tools, you can handle various text-processing tasks in your NLP projects. Feel free to extend this script and customize it for your specific needs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this tutorial, we will explore how to use Python to extract text from Microsoft Word documents (.docx) and filter these documents based on specific terms. \n",
    "\n",
    "This guide is designed for NLP (Natural Language Processing) enthusiasts who are interested in document processing, as well as LLM (Large Language Model) enthusiasts who want to preprocess data for model training.\n",
    "\n",
    "\n",
    "### We'll cover the following topics:\n",
    "\n",
    "Extracting text from .docx files using python-docx.\n",
    "\n",
    "Filtering documents based on the presence of specific allowed and disallowed terms.\n",
    "\n",
    "Extending the script with additional features such as sorting and categorizing documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Before starting, ensure you have the following installed:\n",
    "\n",
    "Python 3.x\n",
    "\n",
    "The python-docx library\n",
    "\n",
    "You can install python-docx using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/envs/rag_AI/lib/python3.12/site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m139.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml, python-docx\n",
      "Successfully installed lxml-5.3.0 python-docx-1.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your_project/\n",
    "│\n",
    "├── docs/\n",
    "│   ├── document1.docx\n",
    "│   ├── document2.docx\n",
    "│   └── document3.docx\n",
    "│\n",
    "└── filter_documents.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extracting Text from Word Documents\n",
    "\n",
    "We start by creating a function to extract text from a .docx file. This is done using the python-docx library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Function to extract text from a Word document\n",
    "# Function to extract text from a Word document\n",
    "def get_doc_text(doc_path):\n",
    "    doc = Document(doc_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \n",
      "\n",
      "Market Analysis \n",
      "\n",
      "Strategy and development plan \n",
      "\n",
      "Context Section\n",
      "\n",
      "Context: High-Frequency Trading (HFT) Industry Overview and the Need for Accessibility\n",
      "\n",
      "Industry Broad Spectrum:\n",
      "The High-Frequency Trading (HFT) industry is a dynamic and influential segment of the financial markets. HFT accounts for a substantial portion of trading activity, especially in the U.S. equities market, where it constitutes approximately 56% of trade volume (Jones et al., 2020). This high level of activity underscores HFT's critical role in modern trading ecosystems.\n",
      "\n",
      "Challenges and Trends:\n",
      "While HFT has introduced efficiencies and liquidity to the market, it also presents significant challenges. Regulatory bodies, such as the SEC in the United States and the European Securities and Markets Authority (ESMA) in Europe, have implemented stringent measures to ensure market integrity and fairness (SEC, 2018). Technological advancements continue to shape the HFT landscape, with firms constantly innovating to maintain competitive advantages through faster execution and more sophisticated algorithms (Brown & White, 2021).\n",
      "\n",
      "Unmet Needs and Accessibility:\n",
      "A major challenge within the HFT industry is the accessibility gap between institutional and retail traders. Proprietary trading firms dominate the HFT space, leveraging substantial technological and financial resources that are often beyond the reach of retail investors. There is a pressing need to democratize HFT by providing retail traders with access to advanced trading tools and platforms. By addressing this unmet need, the financial industry can empower a broader range of participants, enhancing market inclusivity and fairness (BCG, 2011).\n",
      "\n",
      "Bottom Line:\n",
      "The HFT industry, characterized by rapid technological advancements and significant market impact, presents both challenges and opportunities. To harness its full potential, it is crucial to make HFT tools more accessible to retail traders, thereby democratizing high-speed trading and fostering a more inclusive financial market.\n",
      "\n",
      "---\n",
      "\n",
      "Market Analysis Section\n",
      "\n",
      "Market Analysis: Understanding the Target Market for High-Speed Trading Platforms\n",
      "\n",
      "Market Segmentation:\n",
      "The primary focus of our high-frequency trading (HFT) platform is retail investors. This segment includes individual traders who seek to leverage high-speed trading capabilities similar to those of institutional players. Our market research indicates a growing interest among retail investors in sophisticated trading tools that offer speed and efficiency.\n",
      "\n",
      "Data Requirements:\n",
      "To effectively analyze and understand our target market, we must collect and analyze various data points, including trading volumes, investor behavior, market liquidity, and historical price data. These data sets will provide critical insights into market trends and preferences, enabling us to tailor our platform to meet the specific needs of retail traders.\n",
      "\n",
      "Analytical Methodology:\n",
      "Our market analysis will employ a combination of statistical analysis and machine learning algorithms. Statistical methods will help identify trends, patterns, and correlations within the market data, while machine learning algorithms will enhance our platform's real-time data analysis and predictive modeling capabilities. This dual approach will enable us to provide users with valuable trading insights and recommendations, adapting to changing market conditions dynamically.\n",
      "\n",
      "Conclusion:\n",
      "Our market analysis underscores the potential of catering to retail investors seeking accessible high-frequency trading platforms. By leveraging data-driven insights and advanced analytical methodologies, we aim to position our platform as a valuable and user-centric solution in the dynamic world of high-speed trading.\n",
      "\n",
      "---\n",
      "\n",
      "Strategy and Development Plan Section\n",
      "\n",
      "Strategy and Development Plan\n",
      "\n",
      "Strategic Objectives:\n",
      "Our key strategic objectives over the next 3-5 years include:\n",
      "1. Establishing a strong market presence in the retail HFT segment.\n",
      "2. Continuously enhancing our platform's technological capabilities to maintain a competitive edge.\n",
      "3. Expanding our user base by targeting emerging markets and underrepresented trader segments.\n",
      "4. Ensuring regulatory compliance and fostering a secure trading environment.\n",
      "\n",
      "Major Strategic Actions:\n",
      "To achieve these objectives, we will undertake the following strategic actions:\n",
      "1. Product Development: Invest in ongoing research and development to enhance our platform's features and performance.\n",
      "2. Market Expansion: Implement targeted marketing campaigns to attract retail traders in new and emerging markets.\n",
      "3. Partnerships and Collaborations: Forge strategic alliances with financial institutions and technology providers to enhance our platform's value proposition.\n",
      "4. Regulatory Compliance: Develop robust compliance frameworks to adhere to evolving regulatory standards and ensure market integrity.\n",
      "\n",
      "Key Risk Factors and Mitigation Strategies:\n",
      "1. Regulatory Changes: Monitor regulatory developments closely and adapt our platform to comply with new regulations.\n",
      "2. Technological Risks: Invest in cutting-edge cybersecurity measures to protect against potential threats and ensure data integrity.\n",
      "\n",
      "\n",
      "3. Market Volatility: Implement advanced risk management tools to help users navigate volatile market conditions.\n",
      "\n",
      "Conclusion:\n",
      "Our strategy and development plan outlines a clear path to achieving our strategic objectives by focusing on product innovation, market expansion, strategic partnerships, and regulatory compliance. By addressing key risk factors and leveraging our strengths, we aim to establish a leading position in the retail HFT market.\n",
      "\n",
      "\n",
      "Context Section\n",
      "Context: High-Frequency Trading (HFT) Industry Overview and the Need for Accessibility\n",
      "Industry Broad Spectrum: The High-Frequency Trading (HFT) industry is a dynamic and influential segment of the financial markets. HFT accounts for a substantial portion of trading activity, especially in the U.S. equities market, where it constitutes approximately 56% of trade volume (Jones et al., 2020). This high level of activity underscores HFT's critical role in modern trading ecosystems, providing liquidity and contributing to efficient market functioning.\n",
      "Challenges and Trends: While HFT has introduced efficiencies and liquidity to the market, it also presents significant challenges. Regulatory bodies, such as the SEC in the United States and the European Securities and Markets Authority (ESMA) in Europe, have implemented stringent measures to ensure market integrity and fairness (SEC, 2018). These regulations aim to mitigate risks associated with high-speed trading, such as market manipulation and systemic risks. Technological advancements continue to shape the HFT landscape, with firms constantly innovating to maintain competitive advantages through faster execution and more sophisticated algorithms (Brown & White, 2021). The constant evolution of technology means that firms must continuously invest in new systems to stay competitive, which can be a barrier for new entrants and smaller players.\n",
      "Unmet Needs and Accessibility: A major challenge within the HFT industry is the accessibility gap between institutional and retail traders. Proprietary trading firms dominate the HFT space, leveraging substantial technological and financial resources that are often beyond the reach of retail investors. This creates a disparity where institutional players can benefit from advanced trading strategies, while retail traders are left with less sophisticated tools. There is a pressing need to democratize HFT by providing retail traders with access to advanced trading tools and platforms. By addressing this unmet need, the financial industry can empower a broader range of participants, enhancing market inclusivity and fairness (BCG, 2011). Providing retail traders with these tools could lead to more competitive markets and increase overall market participation.\n",
      "Overall, the HFT industry, characterized by rapid technological advancements and significant market impact, presents both challenges and opportunities. To harness its full potential, it is crucial to make HFT tools more accessible to retail traders, thereby democratizing high-speed trading and fostering a more inclusive financial market. This democratization can lead to a more vibrant trading environment, where more participants can contribute to and benefit from market activities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = get_doc_text(\"BP.docx\")\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filtering Documents Based on Specific Terms\n",
    "\n",
    "Next, we create a function that checks whether a document contains any of the allowed terms and excludes those with disallowed terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if document contains any of the allowed terms and excludes the disallowed ones\n",
    "def contains_specific_terms(text, allowed_terms, disallowed_terms):\n",
    "    contains_allowed = any(term in text for term in allowed_terms)\n",
    "    contains_disallowed = any(term in text for term in disallowed_terms)\n",
    "    return contains_allowed and not contains_disallowed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage:\n",
    "\n",
    "This function is useful for filtering out documents that are irrelevant based on your criteria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the Word documents\n",
    "directory = \"/Users/skalaliya/Desktop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document does not meet the criteria\n"
     ]
    }
   ],
   "source": [
    "allowed_terms = [\"C0\", \"C1\", \"C2\"]\n",
    "disallowed_terms = [\"C3\", \"C4\", \"C5\"]\n",
    "\n",
    "text = get_doc_text(\"BP.docx\")\n",
    "if contains_specific_terms(text, allowed_terms, disallowed_terms):\n",
    "    print(\"Document meets the criteria\")\n",
    "else:\n",
    "    print(\"Document does not meet the criteria\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing Multiple Documents\n",
    "\n",
    "We can now use these functions to process multiple documents in a directory. \n",
    "\n",
    "We will filter them based on the terms and then sort them by filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BP.docx',\n",
       " 'DACE Final Project.docx',\n",
       " 'EDB_Fall 2023_Template Orange - Case study.docx',\n",
       " 'ACTE MRIAGE -2 marocain aya.docx',\n",
       " 'sgement 2.docx',\n",
       " '4 SLIDES BDH.docx']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing the Word documents\n",
    "directory = '/Users/skalaliya/Desktop'  #\"path_to_your_directory\"\n",
    "# Get a list of all .docx files in the directory\n",
    "docx_files = [f for f in os.listdir(directory) if f.endswith('.docx')]\n",
    "\n",
    "docx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of tuples (file_name, document_text)\n",
    "filtered_docs = []\n",
    "\n",
    "for file in docx_files:\n",
    "    doc_path = os.path.join(directory, file)\n",
    "    text = get_doc_text(doc_path)\n",
    "    if contains_specific_terms(text, allowed_terms, disallowed_terms):\n",
    "        filtered_docs.append((file, text))\n",
    "print(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Optionally, sort the documents by content or any other criteria\n",
    "sorted_docs = sorted(filtered_docs, key=lambda x: x[0])  # Sort by file name\n",
    "sorted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print or process the filtered and sorted documents\n",
    "for doc_name, text in sorted_docs:\n",
    "    print(f\"Document: {doc_name}, First Line: {text.splitlines()[0] if text else 'Empty Document'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Scenarios:\n",
    "\n",
    "**Filtering Sensitive Documents:** Imagine you are working on a project where you need to filter out documents containing confidential information (e.g., terms like \"confidential\" or \"private\") while keeping those that are public.\n",
    "\n",
    "**Categorizing Documents by Topic:** You can categorize documents by checking for the presence of specific keywords. For instance, categorize documents related to \"Finance\", \"Technology\", or \"Health\" by looking for these terms.\n",
    "\n",
    "**Quality Assurance in Data Collection: **Use this script to ensure that only relevant documents are included in your dataset for training a language model, by filtering out documents that do not meet your criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Advanced Features and Extensions\n",
    "\n",
    "**Adding a User Interface:**\n",
    "\n",
    "You can add a simple user interface using tkinter to allow users to select directories and input terms interactively.\n",
    "\n",
    "**Storing Filtered Results in a File:**\n",
    "\n",
    "Extend the script to save the names of filtered documents and their content to a CSV file or another format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Save filtered document info to a CSV file\n",
    "with open('filtered_documents.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Document Name\", \"First Line\"])\n",
    "    for doc_name, text in sorted_docs:\n",
    "        writer.writerow([doc_name, text.splitlines()[0] if text else 'Empty Document'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting by Content Length:\n",
    "\n",
    "Sort the documents by the length of their content instead of their filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_docs = sorted(filtered_docs, key=lambda x: len(x[1]))  # Sort by content length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending the Script with Examples\n",
    "\n",
    "Here are a few examples and scenarios where this script could be extended:\n",
    "\n",
    "Example 1: Filtering by Multiple Sets of Terms\n",
    "\n",
    "Suppose you want to filter documents based on different sets of allowed and disallowed terms. \n",
    "\n",
    "You could extend the script to handle multiple sets of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_sets = [\n",
    "    {\"allowed\": [\"A1\", \"A2\"], \"disallowed\": [\"B1\", \"B2\"]},\n",
    "    {\"allowed\": [\"C1\", \"C2\"], \"disallowed\": [\"D1\", \"D2\"]},\n",
    "]\n",
    "\n",
    "for terms in term_sets:\n",
    "    allowed_terms = terms[\"allowed\"]\n",
    "    disallowed_terms = terms[\"disallowed\"]\n",
    "\n",
    "    # Filter and process documents using the same logic as before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Saving Filtered Documents to a New Directory\n",
    "\n",
    "If you want to save the filtered documents to a new directory instead of just printing them, you can modify the script to write the filtered text to new files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"filtered_docs\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "for doc_name, text in sorted_docs:\n",
    "    output_path = os.path.join(output_directory, doc_name)\n",
    "    with open(output_path.replace('.docx', '.txt'), 'w') as f:\n",
    "        f.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying NLP Techniques to Filtered Text\n",
    "\n",
    "Once you've filtered the documents, you might want to apply further NLP techniques, such as sentiment analysis or keyword extraction, using libraries like nltk, spacy, or transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for doc_name, text in sorted_docs:\n",
    "    tokens = word_tokenize(text)\n",
    "    print(f\"Document: {doc_name}, Number of Tokens: {len(tokens)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filtered and sorted documents have been copied to the output directory.\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to extract text from a Word document\n",
    "def get_doc_text(doc_path):\n",
    "    doc = Document(doc_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "# Function to check if document contains any of the allowed terms and excludes the disallowed ones\n",
    "def contains_specific_terms(text, allowed_terms, disallowed_terms):\n",
    "    contains_allowed = any(term in text for term in allowed_terms)\n",
    "    contains_disallowed = any(term in text for term in disallowed_terms)\n",
    "    return contains_allowed and not contains_disallowed\n",
    "\n",
    "# Directory containing the Word documents\n",
    "directory = \"/Users/skalaliya/Desktop\"\n",
    "output_directory = \"/Users/skalaliya/Desktop/filtered_docs\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Terms to include and exclude\n",
    "allowed_terms = [\"C0\", \"C1\", \"C2\"]\n",
    "disallowed_terms = [\"C3\", \"C4\", \"C5\"]\n",
    "\n",
    "# Get a list of all .docx files in the directory\n",
    "docx_files = [f for f in os.listdir(directory) if f.endswith('.docx')]\n",
    "\n",
    "# Create a list of tuples (file_name, document_text)\n",
    "filtered_docs = []\n",
    "\n",
    "for file in docx_files:\n",
    "    doc_path = os.path.join(directory, file)\n",
    "    text = get_doc_text(doc_path)\n",
    "    if contains_specific_terms(text, allowed_terms, disallowed_terms):\n",
    "        filtered_docs.append((file, text))\n",
    "\n",
    "# Optionally, sort the documents by content or any other criteria\n",
    "sorted_docs = sorted(filtered_docs, key=lambda x: x[0])  # Sort by file name, or modify as needed\n",
    "\n",
    "# Save copies of the filtered and sorted documents to the output directory\n",
    "for doc_name, _ in sorted_docs:\n",
    "    src_path = os.path.join(directory, doc_name)\n",
    "    dest_path = os.path.join(output_directory, doc_name)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"Copied {doc_name} to {output_directory}\")\n",
    "\n",
    "print(\"All filtered and sorted documents have been copied to the output directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here’s a simple command to copy all .docx files from one directory to another without any filtering or conditions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Use files below:\n",
    "\n",
    "Replace the source_directory and output_directory paths as needed for your specific use case.\n",
    "\n",
    "Copy and paste the code into a Python script.\n",
    "\n",
    "Run the script, and it will copy all files of the specified type from the source directory to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied BP.docx to /Users/skalaliya/Desktop/all_docs\n",
      "Copied DACE Final Project.docx to /Users/skalaliya/Desktop/all_docs\n",
      "Copied EDB_Fall 2023_Template Orange - Case study.docx to /Users/skalaliya/Desktop/all_docs\n",
      "Copied ACTE MRIAGE -2 marocain aya.docx to /Users/skalaliya/Desktop/all_docs\n",
      "Copied sgement 2.docx to /Users/skalaliya/Desktop/all_docs\n",
      "Copied 4 SLIDES BDH.docx to /Users/skalaliya/Desktop/all_docs\n",
      "All .docx files have been copied to the '/Users/skalaliya/Desktop/all_docs' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directory containing the Word documents\n",
    "source_directory = \"/Users/skalaliya/Desktop\"\n",
    "output_directory = \"/Users/skalaliya/Desktop/all_docs\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all .docx files in the source directory\n",
    "docx_files = [f for f in os.listdir(source_directory) if f.endswith('.docx')]\n",
    "\n",
    "# Copy each .docx file to the output directory\n",
    "for file in docx_files:\n",
    "    src_path = os.path.join(source_directory, file)\n",
    "    dest_path = os.path.join(output_directory, file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"Copied {file} to {output_directory}\")\n",
    "\n",
    "print(f\"All .docx files have been copied to the '{output_directory}' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Excel Files (.xlsx and .xls):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied fastfood_data.xlsx to /Users/skalaliya/Desktop/all_excel_files\n",
      "All Excel files have been copied to the '/Users/skalaliya/Desktop/all_excel_files' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directory containing the Excel files\n",
    "source_directory = \"/Users/skalaliya/Desktop\"\n",
    "output_directory = \"/Users/skalaliya/Desktop/all_excel_files\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all .xlsx and .xls files in the source directory\n",
    "excel_files = [f for f in os.listdir(source_directory) if f.endswith(('.xlsx', '.xls'))]\n",
    "\n",
    "# Copy each Excel file to the output directory\n",
    "for file in excel_files:\n",
    "    src_path = os.path.join(source_directory, file)\n",
    "    dest_path = os.path.join(output_directory, file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"Copied {file} to {output_directory}\")\n",
    "\n",
    "print(f\"All Excel files have been copied to the '{output_directory}' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For PowerPoint Files (.pptx and .ppt):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied Formation GIT Bitbucket.pptx to /Users/skalaliya/Desktop/all_ppt_files\n",
      "Copied CV Elliot.pptx to /Users/skalaliya/Desktop/all_ppt_files\n",
      "Copied McCabeStrategicEntryDeterrenceWeek7_edit.pptx to /Users/skalaliya/Desktop/all_ppt_files\n",
      "All PowerPoint files have been copied to the '/Users/skalaliya/Desktop/all_ppt_files' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directory containing the PowerPoint files\n",
    "source_directory = \"/Users/skalaliya/Desktop\"\n",
    "output_directory = \"/Users/skalaliya/Desktop/all_ppt_files\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all .pptx and .ppt files in the source directory\n",
    "ppt_files = [f for f in os.listdir(source_directory) if f.endswith(('.pptx', '.ppt'))]\n",
    "\n",
    "# Copy each PowerPoint file to the output directory\n",
    "for file in ppt_files:\n",
    "    src_path = os.path.join(source_directory, file)\n",
    "    dest_path = os.path.join(output_directory, file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"Copied {file} to {output_directory}\")\n",
    "\n",
    "print(f\"All PowerPoint files have been copied to the '{output_directory}' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For PDF Files (.pdf):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied https___evisa.imigrasi.go.id_web_visa-status_z4gIku0korktNszWis4xNaZzur1SLNuO9bJ+AwOC7nS9STmPxcvcQLPLJh2CmgQ3.pdf to /Users/skalaliya/Desktop/all_pdf_files\n",
      "Copied Aya_Passport.pdf to /Users/skalaliya/Desktop/all_pdf_files\n",
      "All PDF files have been copied to the '/Users/skalaliya/Desktop/all_pdf_files' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directory containing the PDF files\n",
    "source_directory = \"/Users/skalaliya/Desktop\"\n",
    "output_directory = \"/Users/skalaliya/Desktop/all_pdf_files\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all .pdf files in the source directory\n",
    "pdf_files = [f for f in os.listdir(source_directory) if f.endswith('.pdf')]\n",
    "\n",
    "# Copy each PDF file to the output directory\n",
    "for file in pdf_files:\n",
    "    src_path = os.path.join(source_directory, file)\n",
    "    dest_path = os.path.join(output_directory, file)\n",
    "    shutil.copy(src_path, dest_path)\n",
    "    print(f\"Copied {file} to {output_directory}\")\n",
    "\n",
    "print(f\"All PDF files have been copied to the '{output_directory}' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
